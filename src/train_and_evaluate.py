#!/usr/bin/env python3
"""
Script chÃ­nh Ä‘á»ƒ training vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ML cho Fire Detection
"""

import os
import sys
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Import cÃ¡c module tá»± táº¡o
from fire_feature_extractor import DatasetLoader
from ml_models import MLModelTrainer

def setup_environment():
    """Thiáº¿t láº­p mÃ´i trÆ°á»ng"""
    print("ğŸš€ Thiáº¿t láº­p mÃ´i trÆ°á»ng...")
    
    # Táº¡o cÃ¡c thÆ° má»¥c cáº§n thiáº¿t
    directories = ['trained_models', 'results', 'plots', 'logs']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"ğŸ“ Táº¡o thÆ° má»¥c: {directory}")
    
    # Thiáº¿t láº­p matplotlib
    plt.style.use('default')
    sns.set_palette("husl")
    
    print("âœ… MÃ´i trÆ°á»ng Ä‘Ã£ sáºµn sÃ ng!")

def load_and_prepare_data(dataset_path: str, max_samples: int = None):
    """Load vÃ  chuáº©n bá»‹ dá»¯ liá»‡u"""
    print(f"\nğŸ“ Loading dataset tá»«: {dataset_path}")
    
    # Kiá»ƒm tra dataset path
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"Dataset path khÃ´ng tá»“n táº¡i: {dataset_path}")
    
    # Load dataset
    loader = DatasetLoader(dataset_path)
    X, y, image_paths = loader.load_dataset(max_samples=max_samples)
    
    print(f"ğŸ“Š Dataset shape: {X.shape}")
    print(f"ğŸ¯ Labels distribution: {np.bincount(y)}")
    
    return X, y, image_paths

def train_models(X: np.ndarray, y: np.ndarray, use_grid_search: bool = True):
    """Training táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh"""
    print(f"\nğŸ”¥ Báº¯t Ä‘áº§u training cÃ¡c mÃ´ hÃ¬nh...")
    
    # Khá»Ÿi táº¡o trainer
    trainer = MLModelTrainer()
    
    # Training táº¥t cáº£ mÃ´ hÃ¬nh
    X_test, y_test = trainer.train_all_models(X, y, use_grid_search=use_grid_search)
    
    return trainer, X_test, y_test

def evaluate_and_compare(trainer: MLModelTrainer, X_test: np.ndarray, y_test: np.ndarray):
    """ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh"""
    print(f"\nğŸ“Š ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh...")
    
    # So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh
    comparison_df = trainer.compare_models()
    
    # Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh
    print("\nğŸ“ˆ Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Plot results
    results_plot_path = f"plots/model_comparison_{timestamp}.png"
    trainer.plot_results(save_path=results_plot_path)
    
    # Plot confusion matrices
    cm_plot_path = f"plots/confusion_matrices_{timestamp}.png"
    trainer.plot_confusion_matrices(save_path=cm_plot_path)
    
    # Plot ROC curves
    roc_plot_path = f"plots/roc_curves_{timestamp}.png"
    trainer.plot_roc_curves(X_test, y_test, save_path=roc_plot_path)
    
    return comparison_df

def save_results(trainer: MLModelTrainer, comparison_df: pd.DataFrame):
    """LÆ°u káº¿t quáº£ training"""
    print(f"\nğŸ’¾ LÆ°u káº¿t quáº£...")
    
    # LÆ°u models
    trainer.save_models()
    
    # LÆ°u comparison table
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    comparison_path = f"results/model_comparison_{timestamp}.csv"
    comparison_df.to_csv(comparison_path, index=False)
    print(f"ğŸ“Š Báº£ng so sÃ¡nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {comparison_path}")
    
    # LÆ°u summary
    summary_path = f"results/training_summary_{timestamp}.txt"
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("ğŸ”¥ FIRE DETECTION - ML MODELS TRAINING SUMMARY\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Number of Models: {len(trainer.results)}\n\n")
        
        f.write("MODEL COMPARISON:\n")
        f.write("-" * 30 + "\n")
        f.write(comparison_df.to_string(index=False, float_format='%.4f'))
        f.write("\n\n")
        
        f.write("BEST MODEL:\n")
        f.write("-" * 30 + "\n")
        best_model = comparison_df.iloc[0]
        f.write(f"Model: {best_model['Model']}\n")
        f.write(f"F1-Score: {best_model['F1-Score']:.4f}\n")
        f.write(f"Accuracy: {best_model['Accuracy']:.4f}\n")
        f.write(f"Precision: {best_model['Precision']:.4f}\n")
        f.write(f"Recall: {best_model['Recall']:.4f}\n")
        f.write(f"ROC AUC: {best_model['ROC AUC']:.4f}\n")
    
    print(f"ğŸ“ Summary Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {summary_path}")

def test_single_image(trainer: MLModelTrainer, image_path: str):
    """Test má»™t áº£nh vá»›i táº¥t cáº£ mÃ´ hÃ¬nh"""
    print(f"\nğŸ” Testing áº£nh: {image_path}")
    
    if not os.path.exists(image_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh: {image_path}")
        return
    
    try:
        # Dá»± Ä‘oÃ¡n vá»›i táº¥t cáº£ mÃ´ hÃ¬nh
        predictions = trainer.predict_single_image(image_path)
        
        print("\nğŸ“Š Káº¿t quáº£ dá»± Ä‘oÃ¡n:")
        print("-" * 50)
        
        for model_name, pred in predictions.items():
            print(f"\n{model_name}:")
            print(f"  Prediction: {pred['prediction']}")
            print(f"  Confidence: {pred['confidence']:.3f}")
            print(f"  P(Fire): {pred['probability_fire']:.3f}")
            print(f"  P(No Fire): {pred['probability_no_fire']:.3f}")
        
        # TÃ¬m mÃ´ hÃ¬nh cÃ³ confidence cao nháº¥t
        best_model = max(predictions.items(), key=lambda x: x[1]['confidence'])
        print(f"\nğŸ† MÃ´ hÃ¬nh tá»‘t nháº¥t: {best_model[0]} (Confidence: {best_model[1]['confidence']:.3f})")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi test áº£nh: {e}")

def main():
    """HÃ m chÃ­nh"""
    parser = argparse.ArgumentParser(description='Training vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ML cho Fire Detection')
    parser.add_argument('--dataset', type=str, default='../dataset', 
                       help='ÄÆ°á»ng dáº«n Ä‘áº¿n dataset')
    parser.add_argument('--max-samples', type=int, default=3000,
                       help='Sá»‘ lÆ°á»£ng máº«u tá»‘i Ä‘a Ä‘á»ƒ training (default: 3000)')
    parser.add_argument('--no-grid-search', action='store_true',
                       help='KhÃ´ng sá»­ dá»¥ng Grid Search (chá»‰ dÃ¹ng default parameters)')
    parser.add_argument('--test-size', type=float, default=0.2,
                       help='Tá»· lá»‡ test set (default: 0.2)')
    parser.add_argument('--cv-folds', type=int, default=5,
                       help='Sá»‘ fold cho cross-validation (default: 5)')
    parser.add_argument('--test-image', type=str, default=None,
                       help='ÄÆ°á»ng dáº«n Ä‘áº¿n áº£nh Ä‘á»ƒ test')
    parser.add_argument('--load-models', type=str, default=None,
                       help='Load models tá»« timestamp')
    
    args = parser.parse_args()
    
    print("ğŸ”¥ FIRE DETECTION - ML MODELS TRAINING & EVALUATION")
    print("=" * 60)
    
    # Thiáº¿t láº­p mÃ´i trÆ°á»ng
    setup_environment()
    
    # Khá»Ÿi táº¡o trainer
    trainer = MLModelTrainer()
    
    # Load models náº¿u cÃ³
    if args.load_models:
        print(f"\nğŸ“‚ Loading models tá»« timestamp: {args.load_models}")
        trainer.load_models(args.load_models)
        
        if args.test_image:
            test_single_image(trainer, args.test_image)
        return
    
    # Load vÃ  chuáº©n bá»‹ dá»¯ liá»‡u
    X, y, image_paths = load_and_prepare_data(args.dataset, args.max_samples)
    
    # Training cÃ¡c mÃ´ hÃ¬nh
    use_grid_search = not args.no_grid_search
    trainer, X_test, y_test = train_models(X, y, use_grid_search)
    
    # ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh
    comparison_df = evaluate_and_compare(trainer, X_test, y_test)
    
    # LÆ°u káº¿t quáº£
    save_results(trainer, comparison_df)
    
    # Test áº£nh náº¿u cÃ³
    if args.test_image:
        test_single_image(trainer, args.test_image)
    
    print(f"\nâœ… HoÃ n thÃ nh training vÃ  Ä‘Ã¡nh giÃ¡!")
    print(f"ğŸ“Š Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c: results/")
    print(f"ğŸ“ˆ Biá»ƒu Ä‘á»“ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c: plots/")
    print(f"ğŸ’¾ Models Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c: trained_models/")

if __name__ == "__main__":
    main() 