import cv2
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-GUI backend
import matplotlib.pyplot as plt
import os
from datetime import datetime
import json
from typing import Dict, List, Tuple, Any
import seaborn as sns

class DetailedFireAnalyzer:
    """
    H·ªá th·ªëng ph√¢n t√≠ch l·ª≠a chi ti·∫øt v·ªõi t·ª´ng b∆∞·ªõc r√µ r√†ng
    """
    
    def __init__(self, output_dir="results/"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # ƒê·ªãnh nghƒ©a c√°c ng∆∞·ª°ng m√†u l·ª≠a
        self.fire_color_ranges = {
            'red_lower': np.array([0, 100, 100]),
            'red_upper': np.array([10, 255, 255]),
            'orange_lower': np.array([10, 100, 100]),
            'orange_upper': np.array([25, 255, 255]),
            'yellow_lower': np.array([25, 100, 100]),
            'yellow_upper': np.array([35, 255, 255])
        }
        
        # Ng∆∞·ª°ng ph√¢n lo·∫°i
        self.thresholds = {
            'fire_ratio_min': 0.02,  # 2% di·ªán t√≠ch t·ªëi thi·ªÉu
            'fire_brightness_min': 150,  # ƒê·ªô s√°ng t·ªëi thi·ªÉu
            'fire_saturation_min': 100,  # ƒê·ªô b√£o h√≤a t·ªëi thi·ªÉu
            'texture_entropy_min': 4.0,  # Entropy texture t·ªëi thi·ªÉu
            'color_histogram_fire_ratio_min': 0.1  # T·ª∑ l·ªá m√†u l·ª≠a trong histogram
        }
    
    def analyze_image_step_by_step(self, image_path: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch ·∫£nh t·ª´ng b∆∞·ªõc chi ti·∫øt
        """
        print(f"üî• B·∫Øt ƒë·∫ßu ph√¢n t√≠ch ·∫£nh: {image_path}")
        
        # B∆∞·ªõc 1: Load v√† preprocess ·∫£nh
        step1_result = self._step1_load_and_preprocess(image_path)
        
        # B∆∞·ªõc 2: Ph√¢n t√≠ch m√†u s·∫Øc
        step2_result = self._step2_color_analysis(step1_result)
        
        # B∆∞·ªõc 3: Ph√¢n t√≠ch v√πng l·ª≠a
        step3_result = self._step3_fire_region_analysis(step1_result, step2_result)
        
        # B∆∞·ªõc 4: Ph√¢n t√≠ch texture
        step4_result = self._step4_texture_analysis(step1_result)
        
        # B∆∞·ªõc 5: Ph√¢n t√≠ch histogram
        step5_result = self._step5_histogram_analysis(step1_result)
        
        # B∆∞·ªõc 6: T·ªïng h·ª£p k·∫øt qu·∫£
        final_result = self._step6_final_classification(
            step1_result, step2_result, step3_result, step4_result, step5_result
        )
        
        # B∆∞·ªõc 7: T·∫°o b√°o c√°o chi ti·∫øt
        report = self._step7_generate_detailed_report(
            image_path, step1_result, step2_result, step3_result, 
            step4_result, step5_result, final_result
        )
        
        return report
    
    def _step1_load_and_preprocess(self, image_path: str) -> Dict[str, Any]:
        """B∆∞·ªõc 1: Load v√† preprocess ·∫£nh"""
        print("  üì∏ B∆∞·ªõc 1: Load v√† preprocess ·∫£nh...")
        
        # Load ·∫£nh
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Kh√¥ng th·ªÉ load ·∫£nh: {image_path}")
        
        # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
        image = cv2.resize(image, (224, 224))
        
        # Chuy·ªÉn ƒë·ªïi m√†u
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # T√≠nh to√°n th·ªëng k√™ c∆° b·∫£n
        stats = {
            'image_size': image.shape,
            'mean_brightness': np.mean(gray_image),
            'std_brightness': np.std(gray_image),
            'max_brightness': np.max(gray_image),
            'min_brightness': np.min(gray_image)
        }
        
        result = {
            'original': image,
            'rgb': rgb_image,
            'hsv': hsv_image,
            'gray': gray_image,
            'stats': stats
        }
        
        print(f"    ‚úÖ ·∫¢nh ƒë√£ ƒë∆∞·ª£c load: {image.shape}")
        print(f"    üìä ƒê·ªô s√°ng trung b√¨nh: {stats['mean_brightness']:.1f}")
        
        return result
    
    def _step2_color_analysis(self, step1_result: Dict) -> Dict[str, Any]:
        """B∆∞·ªõc 2: Ph√¢n t√≠ch m√†u s·∫Øc"""
        print("  üé® B∆∞·ªõc 2: Ph√¢n t√≠ch m√†u s·∫Øc...")
        
        hsv_image = step1_result['hsv']
        
        # T·∫°o mask cho t·ª´ng m√†u l·ª≠a
        masks = {}
        color_stats = {}
        
        for color_name, (lower, upper) in [
            ('red', (self.fire_color_ranges['red_lower'], self.fire_color_ranges['red_upper'])),
            ('orange', (self.fire_color_ranges['orange_lower'], self.fire_color_ranges['orange_upper'])),
            ('yellow', (self.fire_color_ranges['yellow_lower'], self.fire_color_ranges['yellow_upper']))
        ]:
            mask = cv2.inRange(hsv_image, lower, upper)
            masks[color_name] = mask
            
            # T√≠nh to√°n th·ªëng k√™ cho m√†u n√†y
            color_pixels = np.sum(mask > 0)
            color_ratio = color_pixels / (224 * 224)
            
            color_stats[color_name] = {
                'pixel_count': int(color_pixels),
                'ratio': float(color_ratio),
                'percentage': f"{color_ratio * 100:.2f}%"
            }
        
        # T·∫°o mask t·ªïng h·ª£p cho t·∫•t c·∫£ m√†u l·ª≠a
        combined_mask = masks['red'] | masks['orange'] | masks['yellow']
        
        result = {
            'masks': masks,
            'combined_mask': combined_mask,
            'color_stats': color_stats,
            'total_fire_pixels': int(np.sum(combined_mask > 0)),
            'total_fire_ratio': float(np.sum(combined_mask > 0) / (224 * 224))
        }
        
        print(f"    üî¥ M√†u ƒë·ªè: {color_stats['red']['percentage']}")
        print(f"    üü† M√†u cam: {color_stats['orange']['percentage']}")
        print(f"    üü° M√†u v√†ng: {color_stats['yellow']['percentage']}")
        print(f"    üî• T·ªïng v√πng l·ª≠a: {result['total_fire_ratio']*100:.2f}%")
        
        return result
    
    def _step3_fire_region_analysis(self, step1_result: Dict, step2_result: Dict) -> Dict[str, Any]:
        """B∆∞·ªõc 3: Ph√¢n t√≠ch v√πng l·ª≠a"""
        print("  üî• B∆∞·ªõc 3: Ph√¢n t√≠ch v√πng l·ª≠a...")
        
        combined_mask = step2_result['combined_mask']
        hsv_image = step1_result['hsv']
        
        # T√¨m contours c·ªßa v√πng l·ª≠a
        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # L·ªçc contours c√≥ k√≠ch th∆∞·ªõc ƒë·ªß l·ªõn
        min_contour_area = 50  # T·ªëi thi·ªÉu 50 pixels
        valid_contours = [c for c in contours if cv2.contourArea(c) > min_contour_area]
        
        # Ph√¢n t√≠ch t·ª´ng v√πng l·ª≠a
        fire_regions = []
        total_fire_area = 0
        
        for i, contour in enumerate(valid_contours):
            area = cv2.contourArea(contour)
            total_fire_area += area
            
            # T·∫°o mask cho v√πng n√†y
            region_mask = np.zeros_like(combined_mask)
            cv2.fillPoly(region_mask, [contour], 255)
            
            # T√≠nh to√°n th·ªëng k√™ cho v√πng n√†y
            region_hsv = cv2.bitwise_and(hsv_image, hsv_image, mask=region_mask)
            region_pixels = region_hsv[region_mask > 0]
            
            if len(region_pixels) > 0:
                brightness = np.mean(region_pixels[:, 2])  # V channel
                saturation = np.mean(region_pixels[:, 1])  # S channel
                hue = np.mean(region_pixels[:, 0])  # H channel
            else:
                brightness = saturation = hue = 0
            
            fire_regions.append({
                'id': i,
                'area': int(area),
                'brightness': float(brightness),
                'saturation': float(saturation),
                'hue': float(hue),
                'contour': contour
            })
        
        # T√≠nh to√°n th·ªëng k√™ t·ªïng h·ª£p
        if fire_regions:
            avg_brightness = np.mean([r['brightness'] for r in fire_regions])
            avg_saturation = np.mean([r['saturation'] for r in fire_regions])
            max_brightness = max([r['brightness'] for r in fire_regions])
        else:
            avg_brightness = avg_saturation = max_brightness = 0
        
        result = {
            'fire_regions': fire_regions,
            'total_regions': len(fire_regions),
            'total_fire_area': int(total_fire_area),
            'avg_brightness': float(avg_brightness),
            'avg_saturation': float(avg_saturation),
            'max_brightness': float(max_brightness),
            'fire_area_ratio': float(total_fire_area / (224 * 224))
        }
        
        print(f"    üìä S·ªë v√πng l·ª≠a: {len(fire_regions)}")
        print(f"    üìè T·ªïng di·ªán t√≠ch l·ª≠a: {result['fire_area_ratio']*100:.2f}%")
        print(f"    üí° ƒê·ªô s√°ng trung b√¨nh: {avg_brightness:.1f}")
        print(f"    üé® ƒê·ªô b√£o h√≤a trung b√¨nh: {avg_saturation:.1f}")
        
        return result
    
    def _step4_texture_analysis(self, step1_result: Dict) -> Dict[str, Any]:
        """B∆∞·ªõc 4: Ph√¢n t√≠ch texture"""
        print("  üåÄ B∆∞·ªõc 4: Ph√¢n t√≠ch texture...")
        
        gray_image = step1_result['gray']
        
        # T√≠nh gradient
        grad_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)
        
        # T√≠nh magnitude v√† direction
        magnitude = np.sqrt(grad_x**2 + grad_y**2)
        direction = np.arctan2(grad_y, grad_x)
        
        # T√≠nh to√°n th·ªëng k√™ texture
        texture_stats = {
            'gradient_mean': float(np.mean(magnitude)),
            'gradient_std': float(np.std(magnitude)),
            'gradient_max': float(np.max(magnitude)),
            'direction_mean': float(np.mean(direction)),
            'direction_std': float(np.std(direction))
        }
        
        # T√≠nh entropy c·ªßa gradient
        hist, _ = np.histogram(magnitude.flatten(), bins=50, range=(0, np.max(magnitude)))
        hist = hist[hist > 0]  # Lo·∫°i b·ªè bins c√≥ 0
        if len(hist) > 0:
            prob = hist / np.sum(hist)
            entropy = -np.sum(prob * np.log2(prob))
        else:
            entropy = 0
        
        texture_stats['gradient_entropy'] = float(entropy)
        
        result = {
            'gradient_magnitude': magnitude,
            'gradient_direction': direction,
            'texture_stats': texture_stats
        }
        
        print(f"    üìà Gradient mean: {texture_stats['gradient_mean']:.2f}")
        print(f"    üìä Gradient std: {texture_stats['gradient_std']:.2f}")
        print(f"    üîç Gradient entropy: {texture_stats['gradient_entropy']:.2f}")
        
        return result
    
    def _step5_histogram_analysis(self, step1_result: Dict) -> Dict[str, Any]:
        """B∆∞·ªõc 5: Ph√¢n t√≠ch histogram"""
        print("  üìä B∆∞·ªõc 5: Ph√¢n t√≠ch histogram...")
        
        hsv_image = step1_result['hsv']
        
        # T√≠nh histogram cho t·ª´ng channel
        h_hist = cv2.calcHist([hsv_image], [0], None, [180], [0, 180])
        s_hist = cv2.calcHist([hsv_image], [1], None, [256], [0, 256])
        v_hist = cv2.calcHist([hsv_image], [2], None, [256], [0, 256])
        
        # Chu·∫©n h√≥a histogram
        h_hist = h_hist.flatten() / np.sum(h_hist)
        s_hist = s_hist.flatten() / np.sum(s_hist)
        v_hist = v_hist.flatten() / np.sum(v_hist)
        
        # Ph√¢n t√≠ch m√†u l·ª≠a trong histogram
        # Hue ranges: Red (0-10, 170-180), Orange (10-25), Yellow (25-35)
        red_hue_range = np.concatenate([h_hist[0:11], h_hist[170:181]])
        orange_hue_range = h_hist[10:26]
        yellow_hue_range = h_hist[25:36]
        
        fire_hue_ratio = (np.sum(red_hue_range) + np.sum(orange_hue_range) + np.sum(yellow_hue_range)) / 3
        
        # Ph√¢n t√≠ch saturation v√† value
        high_sat_ratio = np.sum(s_hist[100:]) / np.sum(s_hist)  # Saturation > 100
        high_val_ratio = np.sum(v_hist[150:]) / np.sum(v_hist)  # Value > 150
        
        result = {
            'h_histogram': h_hist.tolist(),
            's_histogram': s_hist.tolist(),
            'v_histogram': v_hist.tolist(),
            'fire_hue_ratio': float(fire_hue_ratio),
            'high_saturation_ratio': float(high_sat_ratio),
            'high_value_ratio': float(high_val_ratio),
            'histogram_stats': {
                'h_mean': float(np.mean(h_hist)),
                'h_std': float(np.std(h_hist)),
                's_mean': float(np.mean(s_hist)),
                's_std': float(np.std(s_hist)),
                'v_mean': float(np.mean(v_hist)),
                'v_std': float(np.std(v_hist))
            }
        }
        
        print(f"    üé® T·ª∑ l·ªá m√†u l·ª≠a trong histogram: {fire_hue_ratio*100:.2f}%")
        print(f"    üìà T·ª∑ l·ªá ƒë·ªô b√£o h√≤a cao: {high_sat_ratio*100:.2f}%")
        print(f"    üí° T·ª∑ l·ªá ƒë·ªô s√°ng cao: {high_val_ratio*100:.2f}%")
        
        return result
    
    def _step6_final_classification(self, step1_result: Dict, step2_result: Dict, 
                                  step3_result: Dict, step4_result: Dict, 
                                  step5_result: Dict) -> Dict[str, Any]:
        """B∆∞·ªõc 6: T·ªïng h·ª£p k·∫øt qu·∫£ v√† ph√¢n lo·∫°i cu·ªëi c√πng"""
        print("  üéØ B∆∞·ªõc 6: T·ªïng h·ª£p k·∫øt qu·∫£ v√† ph√¢n lo·∫°i...")
        
        # Thu th·∫≠p c√°c ch·ªâ s·ªë quan tr·ªçng
        indicators = {
            'fire_ratio': step2_result['total_fire_ratio'],
            'fire_area_ratio': step3_result['fire_area_ratio'],
            'avg_brightness': step3_result['avg_brightness'],
            'avg_saturation': step3_result['avg_saturation'],
            'max_brightness': step3_result['max_brightness'],
            'texture_entropy': step4_result['texture_stats']['gradient_entropy'],
            'fire_hue_ratio': step5_result['fire_hue_ratio'],
            'high_saturation_ratio': step5_result['high_saturation_ratio'],
            'high_value_ratio': step5_result['high_value_ratio']
        }
        
        # Ki·ªÉm tra t·ª´ng ƒëi·ªÅu ki·ªán
        conditions = {
            'has_fire_colors': indicators['fire_ratio'] > self.thresholds['fire_ratio_min'],
            'has_fire_area': indicators['fire_area_ratio'] > self.thresholds['fire_ratio_min'],
            'has_brightness': indicators['avg_brightness'] > self.thresholds['fire_brightness_min'],
            'has_saturation': indicators['avg_saturation'] > self.thresholds['fire_saturation_min'],
            'has_texture': indicators['texture_entropy'] > self.thresholds['texture_entropy_min'],
            'has_fire_histogram': indicators['fire_hue_ratio'] > self.thresholds['color_histogram_fire_ratio_min']
        }
        
        # T√≠nh ƒëi·ªÉm t·ªïng h·ª£p
        score = 0
        total_conditions = len(conditions)
        
        for condition_name, condition_met in conditions.items():
            if condition_met:
                score += 1
                print(f"    ‚úÖ {condition_name}: ƒê·∫°t")
            else:
                print(f"    ‚ùå {condition_name}: Kh√¥ng ƒë·∫°t")
        
        confidence = score / total_conditions
        
        # Ph√¢n lo·∫°i cu·ªëi c√πng
        if confidence >= 0.5:  # √çt nh·∫•t 50% ƒëi·ªÅu ki·ªán ƒë∆∞·ª£c ƒë√°p ·ª©ng
            classification = "FIRE"
            confidence_level = "HIGH" if confidence >= 0.8 else "MEDIUM" if confidence >= 0.6 else "LOW"
        else:
            classification = "NO FIRE"
            confidence_level = "HIGH" if confidence <= 0.2 else "MEDIUM" if confidence <= 0.4 else "LOW"
        
        result = {
            'classification': classification,
            'confidence': float(confidence),
            'confidence_level': confidence_level,
            'score': int(score),
            'total_conditions': total_conditions,
            'indicators': indicators,
            'conditions': conditions,
            'reasoning': self._generate_reasoning(conditions, indicators)
        }
        
        print(f"    üéØ K·∫øt qu·∫£: {classification}")
        print(f"    üìä ƒê·ªô tin c·∫≠y: {confidence*100:.1f}% ({confidence_level})")
        print(f"    üìà ƒêi·ªÉm: {score}/{total_conditions}")
        
        return result
    
    def _generate_reasoning(self, conditions: Dict[str, bool], indicators: Dict[str, float]) -> str:
        """T·∫°o l√Ω do ph√¢n lo·∫°i"""
        met_conditions = [k for k, v in conditions.items() if v]
        failed_conditions = [k for k, v in conditions.items() if not v]
        
        reasoning = "L√Ω do ph√¢n lo·∫°i:\n"
        
        if met_conditions:
            reasoning += "‚úÖ C√°c ƒëi·ªÅu ki·ªán ƒë·∫°t:\n"
            for condition in met_conditions:
                reasoning += f"   - {condition}\n"
        
        if failed_conditions:
            reasoning += "‚ùå C√°c ƒëi·ªÅu ki·ªán kh√¥ng ƒë·∫°t:\n"
            for condition in failed_conditions:
                reasoning += f"   - {condition}\n"
        
        reasoning += f"\nüìä Ch·ªâ s·ªë quan tr·ªçng:\n"
        reasoning += f"   - T·ª∑ l·ªá m√†u l·ª≠a: {indicators['fire_ratio']*100:.2f}%\n"
        reasoning += f"   - Di·ªán t√≠ch l·ª≠a: {indicators['fire_area_ratio']*100:.2f}%\n"
        reasoning += f"   - ƒê·ªô s√°ng trung b√¨nh: {indicators['avg_brightness']:.1f}\n"
        reasoning += f"   - ƒê·ªô b√£o h√≤a trung b√¨nh: {indicators['avg_saturation']:.1f}\n"
        
        return reasoning
    
    def _step7_generate_detailed_report(self, image_path: str, step1_result: Dict, 
                                      step2_result: Dict, step3_result: Dict,
                                      step4_result: Dict, step5_result: Dict,
                                      final_result: Dict) -> Dict[str, Any]:
        """B∆∞·ªõc 7: T·∫°o b√°o c√°o chi ti·∫øt"""
        print("  üìã B∆∞·ªõc 7: T·∫°o b√°o c√°o chi ti·∫øt...")
        
        # T·∫°o t√™n file b√°o c√°o
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        image_name = os.path.basename(image_path).split('.')[0]
        report_filename = f"report_{image_name}_{timestamp}.json"
        report_path = os.path.join(self.output_dir, report_filename)
        
        # T·∫°o b√°o c√°o
        report = {
            'image_path': image_path,
            'analysis_timestamp': timestamp,
            'final_classification': final_result,
            'step_by_step_results': {
                'step1_preprocessing': {
                    'image_stats': step1_result['stats']
                },
                'step2_color_analysis': {
                    'color_stats': step2_result['color_stats'],
                    'total_fire_ratio': step2_result['total_fire_ratio']
                },
                'step3_fire_regions': {
                    'total_regions': step3_result['total_regions'],
                    'fire_area_ratio': step3_result['fire_area_ratio'],
                    'brightness_stats': {
                        'avg': step3_result['avg_brightness'],
                        'max': step3_result['max_brightness']
                    },
                    'saturation_stats': {
                        'avg': step3_result['avg_saturation']
                    }
                },
                'step4_texture': {
                    'texture_stats': step4_result['texture_stats']
                },
                'step5_histogram': {
                    'fire_hue_ratio': step5_result['fire_hue_ratio'],
                    'saturation_ratio': step5_result['high_saturation_ratio'],
                    'value_ratio': step5_result['high_value_ratio']
                }
            },
            'thresholds_used': self.thresholds
        }
        
        # Chuy·ªÉn ƒë·ªïi c√°c tr∆∞·ªùng numpy types sang native types
        def convert(obj):
            if isinstance(obj, np.generic):
                return obj.item()
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            if isinstance(obj, dict):
                return {k: convert(v) for k, v in obj.items()}
            if isinstance(obj, list):
                return [convert(v) for v in obj]
            return obj
        
        report = convert(report)
        
        # L∆∞u b√°o c√°o
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"    üìÑ B√°o c√°o ƒë√£ ƒë∆∞·ª£c l∆∞u: {report_path}")
        
        return report
    
    def visualize_analysis(self, image_path: str, step1_result: Dict, 
                          step2_result: Dict, step3_result: Dict) -> str:
        """T·∫°o visualization cho ph√¢n t√≠ch"""
        print("  üé® T·∫°o visualization...")
        
        # T·∫°o figure v·ªõi subplots
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle(f'Ph√¢n t√≠ch chi ti·∫øt: {os.path.basename(image_path)}', fontsize=16)
        
        # 1. ·∫¢nh g·ªëc
        axes[0, 0].imshow(step1_result['rgb'])
        axes[0, 0].set_title('·∫¢nh g·ªëc')
        axes[0, 0].axis('off')
        
        # 2. ·∫¢nh HSV
        axes[0, 1].imshow(step1_result['hsv'])
        axes[0, 1].set_title('·∫¢nh HSV')
        axes[0, 1].axis('off')
        
        # 3. Mask t·ªïng h·ª£p
        axes[0, 2].imshow(step2_result['combined_mask'], cmap='hot')
        axes[0, 2].set_title('Mask m√†u l·ª≠a t·ªïng h·ª£p')
        axes[0, 2].axis('off')
        
        # 4. Mask t·ª´ng m√†u
        color_masks = step2_result['masks']
        combined_display = np.zeros((224, 224, 3), dtype=np.uint8)
        combined_display[:, :, 0] = color_masks['red']  # Red channel
        combined_display[:, :, 1] = color_masks['orange']  # Green channel  
        combined_display[:, :, 2] = color_masks['yellow']  # Blue channel
        axes[1, 0].imshow(combined_display)
        axes[1, 0].set_title('Mask m√†u ri√™ng bi·ªát\n(ƒê·ªè/Cam/V√†ng)')
        axes[1, 0].axis('off')
        
        # 5. Contours v√πng l·ª≠a
        img_with_contours = step1_result['rgb'].copy()
        for region in step3_result['fire_regions']:
            cv2.drawContours(img_with_contours, [region['contour']], -1, (0, 255, 0), 2)
        axes[1, 1].imshow(img_with_contours)
        axes[1, 1].set_title(f'V√πng l·ª≠a ph√°t hi·ªán\n({len(step3_result["fire_regions"])} v√πng)')
        axes[1, 1].axis('off')
        
        # 6. Th·ªëng k√™ m√†u s·∫Øc
        colors = ['red', 'orange', 'yellow']
        ratios = [step2_result['color_stats'][c]['ratio'] for c in colors]
        axes[1, 2].bar(colors, ratios, color=['red', 'orange', 'yellow'])
        axes[1, 2].set_title('T·ª∑ l·ªá m√†u l·ª≠a')
        axes[1, 2].set_ylabel('T·ª∑ l·ªá')
        axes[1, 2].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # L∆∞u visualization
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        image_name = os.path.basename(image_path).split('.')[0]
        viz_filename = f"visualization_{image_name}_{timestamp}.png"
        viz_path = os.path.join(self.output_dir, viz_filename)
        plt.savefig(viz_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"    üñºÔ∏è Visualization ƒë√£ ƒë∆∞·ª£c l∆∞u: {viz_path}")
        return viz_path

def main():
    """Test h·ªá th·ªëng ph√¢n t√≠ch"""
    analyzer = DetailedFireAnalyzer()
    
    # Test v·ªõi m·ªôt s·ªë ·∫£nh t·ª´ dataset
    test_images = [
        "dataset/train/images/train_1.jpg",
        "dataset/train/images/train_7.jpg", 
        "dataset/train/images/train_155.jpg"
    ]
    
    for image_path in test_images:
        if os.path.exists(image_path):
            print(f"\n{'='*60}")
            print(f"Ph√¢n t√≠ch ·∫£nh: {image_path}")
            print(f"{'='*60}")
            
            try:
                # Ph√¢n t√≠ch chi ti·∫øt
                report = analyzer.analyze_image_step_by_step(image_path)
                
                # T·∫°o visualization
                step1 = analyzer._step1_load_and_preprocess(image_path)
                step2 = analyzer._step2_color_analysis(step1)
                step3 = analyzer._step3_fire_region_analysis(step1, step2)
                viz_path = analyzer.visualize_analysis(image_path, step1, step2, step3)
                
                print(f"\n‚úÖ Ho√†n th√†nh ph√¢n t√≠ch: {image_path}")
                print(f"üìä K·∫øt qu·∫£: {report['final_classification']['classification']}")
                print(f"üéØ ƒê·ªô tin c·∫≠y: {report['final_classification']['confidence']*100:.1f}%")
                
            except Exception as e:
                print(f"‚ùå L·ªói khi ph√¢n t√≠ch {image_path}: {str(e)}")
        else:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")

if __name__ == "__main__":
    main() 