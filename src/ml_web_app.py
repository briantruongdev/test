#!/usr/bin/env python3
"""
Web Application cho ML Models Fire Detection
Cho phÃ©p upload áº£nh vÃ  test vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ train
"""

from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import cv2
import numpy as np
import base64
from datetime import datetime
import uuid
import json
from ml_models import MLModelTrainer
from fire_feature_extractor import FireFeatureExtractor

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# Khá»Ÿi táº¡o trainer vÃ  load models
# Use path relative to this file so it works regardless of current working directory
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODELS_DIR = os.path.join(BASE_DIR, "trained_models")
trainer = MLModelTrainer(models_dir=MODELS_DIR)
feature_extractor = FireFeatureExtractor()

# Load models má»›i nháº¥t náº¿u cÃ³
def load_latest_models():
    """Load models má»›i nháº¥t tá»« thÆ° má»¥c trained_models"""
    models_dir = MODELS_DIR
    if not os.path.exists(models_dir):
        print("âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c trained_models")
        return False
    
    # TÃ¬m timestamp má»›i nháº¥t
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl') and not f.startswith('scaler')]
    if not model_files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y models Ä‘Ã£ train")
        return False
    
    # Láº¥y timestamp tá»« file Ä‘áº§u tiÃªn vÃ  Ä‘áº£m báº£o format Ä‘Ãºng
    first_file = model_files[0]
    # TÃ¬m timestamp Ä‘áº§y Ä‘á»§ (YYYYMMDD_HHMMSS)
    # Format: ModelName_YYYYMMDD_HHMMSS.pkl
    parts = first_file.split('_')
    if len(parts) >= 3:
        # Láº¥y 2 pháº§n cuá»‘i: YYYYMMDD_HHMMSS
        timestamp = f"{parts[-2]}_{parts[-1].replace('.pkl', '')}"
    elif len(parts) >= 2:
        # Fallback: chá»‰ láº¥y pháº§n cuá»‘i
        timestamp = parts[-1].replace('.pkl', '')
    else:
        print("âŒ KhÃ´ng thá»ƒ parse timestamp tá»« filename")
        return False
    
    print(f"ğŸ” TÃ¬m tháº¥y timestamp: {timestamp}")
    print(f"ğŸ“ Model files: {model_files[:3]}...")  # Hiá»ƒn thá»‹ 3 files Ä‘áº§u
    
    try:
        trainer.load_models(timestamp)
        print(f"âœ… ÄÃ£ load models tá»« timestamp: {timestamp}")
        print(f"ğŸ“Š Models loaded: {list(trainer.trained_models.keys())}")
        return True
    except Exception as e:
        print(f"âŒ Lá»—i khi load models: {e}")
        return False

# Thá»­ load models khi khá»Ÿi Ä‘á»™ng
print("ğŸš€ Khá»Ÿi Ä‘á»™ng ML Web Application...")
models_loaded = load_latest_models()
if models_loaded:
    print(f"ğŸ“Š Models Ä‘Ã£ load: {list(trainer.trained_models.keys())}")
else:
    print("ğŸ“Š Models Ä‘Ã£ load: KhÃ´ng cÃ³")

@app.route('/')
def index():
    """Trang chá»§"""
    return render_template('ml_index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """Xá»­ lÃ½ upload áº£nh vÃ  dá»± Ä‘oÃ¡n"""
    if 'file' not in request.files:
        return jsonify({'error': 'KhÃ´ng cÃ³ file Ä‘Æ°á»£c upload'})
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'KhÃ´ng cÃ³ file Ä‘Æ°á»£c chá»n'})
    
    if file:
        # Táº¡o tÃªn file unique
        filename = f"{uuid.uuid4()}_{file.filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        try:
            # Kiá»ƒm tra xem cÃ³ models nÃ o Ä‘Æ°á»£c load khÃ´ng
            if not trainer.trained_models:
                return jsonify({'error': 'ChÆ°a cÃ³ models nÃ o Ä‘Æ°á»£c load. Vui lÃ²ng load models trÆ°á»›c.'})
            
            # Dá»± Ä‘oÃ¡n vá»›i táº¥t cáº£ models
            predictions = trainer.predict_single_image(filepath)
            
            # Chuyá»ƒn Ä‘á»•i numpy types sang native types
            def convert(obj):
                if isinstance(obj, np.generic):
                    return obj.item()
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                if isinstance(obj, dict):
                    return {k: convert(v) for k, v in obj.items()}
                if isinstance(obj, list):
                    return [convert(v) for v in obj]
                return obj
            
            predictions = convert(predictions)
            
            # Äá»c áº£nh Ä‘á»ƒ encode base64
            with open(filepath, "rb") as image_file:
                encoded_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            # Táº¡o response
            response = {
                'success': True,
                'image': encoded_image,
                'predictions': predictions,
                'timestamp': datetime.now().isoformat()
            }
            
            # TÃ¬m model tá»‘t nháº¥t
            best_model = max(predictions.items(), key=lambda x: x[1]['confidence'])
            response['best_model'] = {
                'name': best_model[0],
                'prediction': best_model[1]['prediction'],
                'confidence': best_model[1]['confidence']
            }
            
            return jsonify(response)
            
        except Exception as e:
            return jsonify({'error': f'Lá»—i khi phÃ¢n tÃ­ch áº£nh: {str(e)}'})

@app.route('/uploaded_file/<filename>')
def uploaded_file(filename):
    """Serve uploaded files"""
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/health')
def health_check():
    """Health check endpoint"""
    models_loaded = len(trainer.trained_models) > 0
    return jsonify({
        'status': 'healthy',
        'models_loaded': models_loaded,
        'num_models': len(trainer.trained_models),
        'model_names': list(trainer.trained_models.keys()) if models_loaded else []
    })

@app.route('/models')
def get_models():
    """Láº¥y thÃ´ng tin vá» cÃ¡c models Ä‘Ã£ load"""
    models_info = {}
    for name, model in trainer.trained_models.items():
        models_info[name] = {
            'type': type(model).__name__,
            'parameters': str(model.get_params()) if hasattr(model, 'get_params') else 'N/A'
        }
    
    return jsonify({
        'models_loaded': len(trainer.trained_models),
        'models': models_info
    })

@app.route('/load-models', methods=['POST'])
def load_models_endpoint():
    """Load models tá»« timestamp"""
    data = request.get_json()
    timestamp = data.get('timestamp')
    
    if not timestamp:
        return jsonify({'error': 'Timestamp khÃ´ng Ä‘Æ°á»£c cung cáº¥p'})
    
    try:
        success = load_latest_models() if timestamp == 'latest' else trainer.load_models(timestamp)
        if success:
            return jsonify({
                'success': True,
                'message': f'ÄÃ£ load models thÃ nh cÃ´ng',
                'models': list(trainer.trained_models.keys())
            })
        else:
            return jsonify({'error': 'KhÃ´ng thá»ƒ load models'})
    except Exception as e:
        return jsonify({'error': f'Lá»—i khi load models: {str(e)}'})

@app.route('/train-status')
def train_status():
    """Kiá»ƒm tra tráº¡ng thÃ¡i training"""
    models_dir = MODELS_DIR
    if not os.path.exists(models_dir):
        return jsonify({'status': 'no_models', 'message': 'ChÆ°a cÃ³ models nÃ o Ä‘Æ°á»£c train'})
    
    # TÃ¬m models cÃ³ sáºµn
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl') and not f.startswith('scaler')]
    if not model_files:
        return jsonify({'status': 'no_models', 'message': 'KhÃ´ng tÃ¬m tháº¥y models'})
    
    # Láº¥y thÃ´ng tin vá» models
    timestamps = []
    for f in model_files:
        parts = f.split('_')
        if len(parts) >= 3:
            timestamp = f"{parts[-2]}_{parts[-1].replace('.pkl', '')}"
        else:
            timestamp = parts[-1].replace('.pkl', '')
        timestamps.append(timestamp)
    
    timestamps = list(set(timestamps))
    timestamps.sort(reverse=True)  # Sáº¯p xáº¿p theo thá»i gian má»›i nháº¥t
    
    # Kiá»ƒm tra xem cÃ³ models nÃ o Ä‘Ã£ Ä‘Æ°á»£c load khÃ´ng
    models_loaded = len(trainer.trained_models) > 0
    
    return jsonify({
        'status': 'models_available',
        'available_timestamps': timestamps,
        'latest_timestamp': timestamps[0] if timestamps else None,
        'models_loaded': models_loaded,
        'num_models_loaded': len(trainer.trained_models),
        'model_names': list(trainer.trained_models.keys()) if models_loaded else []
    })

if __name__ == '__main__':
    # Allow cloud platforms (Amplify, etc.) to provide the port via env var
    port = int(os.environ.get('PORT', '8080'))
    # Enable/disable debug via env: DEBUG=true/false
    debug_flag = str(os.environ.get('DEBUG', 'false')).lower() == 'true'
    print("ğŸš€ Khá»Ÿi Ä‘á»™ng ML Web Application...")
    print("ğŸ“Š Models Ä‘Ã£ load:", list(trainer.trained_models.keys()) if trainer.trained_models else "KhÃ´ng cÃ³")
    print(f"ğŸŒ Truy cáº­p: http://localhost:{port}")
    app.run(debug=debug_flag, host='0.0.0.0', port=port)